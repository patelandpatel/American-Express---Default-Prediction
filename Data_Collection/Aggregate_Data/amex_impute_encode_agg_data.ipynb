{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3fc1adf",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-02-09T23:49:04.935322Z",
     "iopub.status.busy": "2023-02-09T23:49:04.934437Z",
     "iopub.status.idle": "2023-02-09T23:49:06.069691Z",
     "shell.execute_reply": "2023-02-09T23:49:06.068346Z"
    },
    "papermill": {
     "duration": 1.144987,
     "end_time": "2023-02-09T23:49:06.072993",
     "exception": false,
     "start_time": "2023-02-09T23:49:04.928006",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import gc\n",
    "import pandas as pd \n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe265279",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-09T23:49:06.081983Z",
     "iopub.status.busy": "2023-02-09T23:49:06.081580Z",
     "iopub.status.idle": "2023-02-09T23:49:06.088356Z",
     "shell.execute_reply": "2023-02-09T23:49:06.086991Z"
    },
    "papermill": {
     "duration": 0.013718,
     "end_time": "2023-02-09T23:49:06.090871",
     "exception": false,
     "start_time": "2023-02-09T23:49:06.077153",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def one_hot_encode(cat_df):\n",
    "    \"\"\"\n",
    "    One-hot encodes categorical features using scikit-learn OneHotEncoder\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    cat_df: pd.DataFrame\n",
    "        DataFrame, with index, that has only the categorical columns to one-hot encode\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        DataFrame that holds each of the one-hot encoded columns \n",
    "    \"\"\"    \n",
    "    \n",
    "    enc = OneHotEncoder(sparse=False)\n",
    "    encoded_df = pd.DataFrame(enc.fit_transform(cat_df), columns=enc.get_feature_names(['D_63_last', 'D_64_last']), index=cat_df.index)\n",
    "    return encoded_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1082a483",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-09T23:49:06.099093Z",
     "iopub.status.busy": "2023-02-09T23:49:06.098430Z",
     "iopub.status.idle": "2023-02-09T23:49:06.106893Z",
     "shell.execute_reply": "2023-02-09T23:49:06.105822Z"
    },
    "papermill": {
     "duration": 0.015619,
     "end_time": "2023-02-09T23:49:06.109659",
     "exception": false,
     "start_time": "2023-02-09T23:49:06.094040",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def impute_helper(col):\n",
    "    \"\"\"\n",
    "    Function to be passed into .apply() to help with imputing the different types of columns.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    col: pd.Series\n",
    "        A column of the DataFrame to be imputed\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.Series\n",
    "        New column imputed with either most common value or mean(), instead of NaNs \n",
    "    \"\"\"        \n",
    "    \n",
    "    cat_features = ['B_30', 'B_38', 'D_114', 'D_116', 'D_117', 'D_120', 'D_126', 'D_63', 'D_64', 'D_66', 'D_68']\n",
    "    convert_dtype = False\n",
    "    \n",
    "    # convert float16's to float32 to calculate means without overflow \n",
    "    if col.dtype == 'float16':\n",
    "        convert_dtype = True\n",
    "        col = col.astype('float32')\n",
    "    \n",
    "    # if the column was originally a categorical feature then fill with the most common value\n",
    "    # otherwise fill with mean()\n",
    "    if '_'.join(col.name.split(\"_\", 2)[:2]) in cat_features:\n",
    "        col = col.fillna(col.value_counts().idxmax())\n",
    "    else: \n",
    "        col = col.fillna(col.mean())\n",
    "        \n",
    "    # convert float16s back \n",
    "    if convert_dtype:\n",
    "        col = col.astype('float16')\n",
    "        \n",
    "    return col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5ecdfaf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-09T23:49:06.117688Z",
     "iopub.status.busy": "2023-02-09T23:49:06.117264Z",
     "iopub.status.idle": "2023-02-09T23:49:06.122780Z",
     "shell.execute_reply": "2023-02-09T23:49:06.121464Z"
    },
    "papermill": {
     "duration": 0.012877,
     "end_time": "2023-02-09T23:49:06.125726",
     "exception": false,
     "start_time": "2023-02-09T23:49:06.112849",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def impute_columns(df):\n",
    "    \"\"\"\n",
    "    Fills NaN values for Aggregate data. Categorical columns are filled with most common value \n",
    "    and numerical are filled with mean.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        DataFrame, with index, that should be imputed\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        DataFrame with no NaN values\n",
    "    \"\"\"\n",
    "\n",
    "    # if the column is a categorical feature fill with the most common value, fill with mean() if column is numerical\n",
    "    df = df.apply(impute_helper)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d44cdb0e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-09T23:49:06.134703Z",
     "iopub.status.busy": "2023-02-09T23:49:06.133754Z",
     "iopub.status.idle": "2023-02-09T23:49:06.143235Z",
     "shell.execute_reply": "2023-02-09T23:49:06.142086Z"
    },
    "papermill": {
     "duration": 0.016689,
     "end_time": "2023-02-09T23:49:06.145807",
     "exception": false,
     "start_time": "2023-02-09T23:49:06.129118",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_x_y(df_file_path, test=False):\n",
    "    \"\"\"\n",
    "    Returns the features (X) and targets (y) for the given data file\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df_file_path : string\n",
    "        File path to generate DataFrame from \n",
    "    test : boolean\n",
    "        Whether or not the provided data file is the test set\n",
    "        False = training set \n",
    "        True = test set \n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        If it is the test dataset it will return only the features (X)\n",
    "        \n",
    "    OR \n",
    "    \n",
    "    Tuple(pd.DataFrame, pd.DataFrame)\n",
    "        If it is the training set it will return the features and targets in a tuple (X, y)\n",
    "    \"\"\"    \n",
    "    \n",
    "    df = pd.read_pickle(df_file_path, compression='gzip')\n",
    "    y = None if test else df['target']\n",
    "    \n",
    "    # D_63_last and D_64_last columns are of type 'category', these are the only columns that need to be one-hot encoded\n",
    "    # the other, original, categorical features are already modified from the aggregate functions\n",
    "    encoded_df = one_hot_encode(df[['D_63_last', 'D_64_last']])\n",
    "    \n",
    "    # impute with numerical columns with mean() and categorical columns with most common value\n",
    "    X = impute_columns(df.drop(['D_63_last', 'D_64_last'], axis=1) if test else df.drop(['D_63_last', 'D_64_last', 'target'], axis=1))\n",
    "    \n",
    "    del df\n",
    "    gc.collect()\n",
    "    \n",
    "    # combine new dataframes and sort them to line up when training/predicting\n",
    "    X = pd.concat([X, encoded_df], axis=1)\n",
    "    \n",
    "    if test: \n",
    "        return X\n",
    "    else: \n",
    "        return (X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd256aa4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-09T23:49:06.154490Z",
     "iopub.status.busy": "2023-02-09T23:49:06.153401Z",
     "iopub.status.idle": "2023-02-09T23:53:44.773972Z",
     "shell.execute_reply": "2023-02-09T23:53:44.772572Z"
    },
    "papermill": {
     "duration": 278.630851,
     "end_time": "2023-02-09T23:53:44.779803",
     "exception": false,
     "start_time": "2023-02-09T23:49:06.148952",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/kaggle/input/amex-agg-data-pickle/train_agg.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m X_train, y_train \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_x_y\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/kaggle/input/amex-agg-data-pickle/train_agg.pkl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m X_train \u001b[38;5;241m=\u001b[39m X_train\u001b[38;5;241m.\u001b[39mreindex(\u001b[38;5;28msorted\u001b[39m(X_train\u001b[38;5;241m.\u001b[39mcolumns), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      4\u001b[0m display(X_train\u001b[38;5;241m.\u001b[39mhead())\n",
      "Cell \u001b[1;32mIn[5], line 25\u001b[0m, in \u001b[0;36mgenerate_x_y\u001b[1;34m(df_file_path, test)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_x_y\u001b[39m(df_file_path, test\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m      2\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m    Returns the features (X) and targets (y) for the given data file\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;124;03m        If it is the training set it will return the features and targets in a tuple (X, y)\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m    \n\u001b[1;32m---> 25\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_pickle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_file_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgzip\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m test \u001b[38;5;28;01melse\u001b[39;00m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;66;03m# D_63_last and D_64_last columns are of type 'category', these are the only columns that need to be one-hot encoded\u001b[39;00m\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;66;03m# the other, original, categorical features are already modified from the aggregate functions\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\io\\pickle.py:185\u001b[0m, in \u001b[0;36mread_pickle\u001b[1;34m(filepath_or_buffer, compression, storage_options)\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;124;03mLoad pickled pandas object (or any object) from file.\u001b[39;00m\n\u001b[0;32m    125\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;124;03m4    4    9\u001b[39;00m\n\u001b[0;32m    183\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    184\u001b[0m excs_to_catch \u001b[38;5;241m=\u001b[39m (\u001b[38;5;167;01mAttributeError\u001b[39;00m, \u001b[38;5;167;01mImportError\u001b[39;00m, \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m)\n\u001b[1;32m--> 185\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    186\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    187\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    188\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    189\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    190\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    191\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[0;32m    192\u001b[0m     \u001b[38;5;66;03m# 1) try standard library Pickle\u001b[39;00m\n\u001b[0;32m    193\u001b[0m     \u001b[38;5;66;03m# 2) try pickle_compat (older pandas version) to handle subclass changes\u001b[39;00m\n\u001b[0;32m    194\u001b[0m     \u001b[38;5;66;03m# 3) try pickle_compat with latin-1 encoding upon a UnicodeDecodeError\u001b[39;00m\n\u001b[0;32m    196\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    197\u001b[0m         \u001b[38;5;66;03m# TypeError for Cython complaints about object.__new__ vs Tick.__new__\u001b[39;00m\n\u001b[0;32m    198\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\io\\common.py:765\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compression \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgzip\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    762\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    763\u001b[0m         \u001b[38;5;66;03m# error: Incompatible types in assignment (expression has type\u001b[39;00m\n\u001b[0;32m    764\u001b[0m         \u001b[38;5;66;03m# \"GzipFile\", variable has type \"Union[str, BaseBuffer]\")\u001b[39;00m\n\u001b[1;32m--> 765\u001b[0m         handle \u001b[38;5;241m=\u001b[39m gzip\u001b[38;5;241m.\u001b[39mGzipFile(  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[0;32m    766\u001b[0m             filename\u001b[38;5;241m=\u001b[39mhandle,\n\u001b[0;32m    767\u001b[0m             mode\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    768\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcompression_args,\n\u001b[0;32m    769\u001b[0m         )\n\u001b[0;32m    770\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    771\u001b[0m         handle \u001b[38;5;241m=\u001b[39m gzip\u001b[38;5;241m.\u001b[39mGzipFile(\n\u001b[0;32m    772\u001b[0m             \u001b[38;5;66;03m# No overload variant of \"GzipFile\" matches argument types\u001b[39;00m\n\u001b[0;32m    773\u001b[0m             \u001b[38;5;66;03m# \"Union[str, BaseBuffer]\", \"str\", \"Dict[str, Any]\"\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    776\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcompression_args,\n\u001b[0;32m    777\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\Parth\\anaconda_new\\envs\\tensorflow\\lib\\gzip.py:174\u001b[0m, in \u001b[0;36mGzipFile.__init__\u001b[1;34m(self, filename, mode, compresslevel, fileobj, mtime)\u001b[0m\n\u001b[0;32m    172\u001b[0m     mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fileobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 174\u001b[0m     fileobj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmyfileobj \u001b[38;5;241m=\u001b[39m \u001b[43mbuiltins\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filename \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    176\u001b[0m     filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(fileobj, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/input/amex-agg-data-pickle/train_agg.pkl'"
     ]
    }
   ],
   "source": [
    "X_train, y_train = generate_x_y('/kaggle/input/amex-agg-data-pickle/train_agg.pkl')\n",
    "X_train = X_train.reindex(sorted(X_train.columns), axis=1)\n",
    "\n",
    "display(X_train.head())\n",
    "\n",
    "X_train.to_pickle('X_train_agg.pkl', compression='gzip')\n",
    "y_train.to_pickle('y_train_agg.pkl', compression='gzip')\n",
    "\n",
    "del X_train, y_train\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a168cfe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-09T23:53:44.789857Z",
     "iopub.status.busy": "2023-02-09T23:53:44.789415Z",
     "iopub.status.idle": "2023-02-10T00:03:04.443754Z",
     "shell.execute_reply": "2023-02-10T00:03:04.442578Z"
    },
    "papermill": {
     "duration": 559.669911,
     "end_time": "2023-02-10T00:03:04.453504",
     "exception": false,
     "start_time": "2023-02-09T23:53:44.783593",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>B_10_last</th>\n",
       "      <th>B_10_max</th>\n",
       "      <th>B_10_mean</th>\n",
       "      <th>B_10_min</th>\n",
       "      <th>B_10_std</th>\n",
       "      <th>B_11_last</th>\n",
       "      <th>B_11_max</th>\n",
       "      <th>B_11_mean</th>\n",
       "      <th>B_11_min</th>\n",
       "      <th>B_11_std</th>\n",
       "      <th>...</th>\n",
       "      <th>S_8_last</th>\n",
       "      <th>S_8_max</th>\n",
       "      <th>S_8_mean</th>\n",
       "      <th>S_8_min</th>\n",
       "      <th>S_8_std</th>\n",
       "      <th>S_9_last</th>\n",
       "      <th>S_9_max</th>\n",
       "      <th>S_9_mean</th>\n",
       "      <th>S_9_min</th>\n",
       "      <th>S_9_std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>customer_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>00000469ba478561f23a92a868bd366de6f6527a684c9a2e78fb826dcac3b9b7</th>\n",
       "      <td>0.033600</td>\n",
       "      <td>0.063171</td>\n",
       "      <td>0.037079</td>\n",
       "      <td>-0.002918</td>\n",
       "      <td>0.017798</td>\n",
       "      <td>0.005188</td>\n",
       "      <td>0.013306</td>\n",
       "      <td>0.006187</td>\n",
       "      <td>0.003296</td>\n",
       "      <td>0.003371</td>\n",
       "      <td>...</td>\n",
       "      <td>0.464111</td>\n",
       "      <td>0.464111</td>\n",
       "      <td>0.271240</td>\n",
       "      <td>0.170776</td>\n",
       "      <td>0.103693</td>\n",
       "      <td>0.016998</td>\n",
       "      <td>0.022949</td>\n",
       "      <td>0.015572</td>\n",
       "      <td>0.010773</td>\n",
       "      <td>0.004110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00001bf2e77ff879fab36aa4fac689b9ba411dae63ae397d4263dafa1daedef5</th>\n",
       "      <td>0.298828</td>\n",
       "      <td>0.303223</td>\n",
       "      <td>0.298096</td>\n",
       "      <td>0.293457</td>\n",
       "      <td>0.002682</td>\n",
       "      <td>0.002235</td>\n",
       "      <td>0.237061</td>\n",
       "      <td>0.035706</td>\n",
       "      <td>0.001258</td>\n",
       "      <td>0.061982</td>\n",
       "      <td>...</td>\n",
       "      <td>0.768555</td>\n",
       "      <td>1.004883</td>\n",
       "      <td>0.840332</td>\n",
       "      <td>0.604980</td>\n",
       "      <td>0.110109</td>\n",
       "      <td>0.018509</td>\n",
       "      <td>0.544434</td>\n",
       "      <td>0.155762</td>\n",
       "      <td>0.018509</td>\n",
       "      <td>0.184704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0000210045da4f81e5f122c6bde5c2a617d03eef67f82c5e400fc98e7bd43ce8</th>\n",
       "      <td>0.129150</td>\n",
       "      <td>0.298828</td>\n",
       "      <td>0.192017</td>\n",
       "      <td>0.079224</td>\n",
       "      <td>0.088889</td>\n",
       "      <td>0.003380</td>\n",
       "      <td>0.025375</td>\n",
       "      <td>0.009048</td>\n",
       "      <td>0.001163</td>\n",
       "      <td>0.007781</td>\n",
       "      <td>...</td>\n",
       "      <td>0.122986</td>\n",
       "      <td>0.759766</td>\n",
       "      <td>0.336182</td>\n",
       "      <td>0.007782</td>\n",
       "      <td>0.204347</td>\n",
       "      <td>0.009171</td>\n",
       "      <td>0.551270</td>\n",
       "      <td>0.081970</td>\n",
       "      <td>0.001582</td>\n",
       "      <td>0.175943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00003b41e58ede33b8daf61ab56d9952f17c9ad1c3976cf6e56734528702d694</th>\n",
       "      <td>0.032135</td>\n",
       "      <td>0.032135</td>\n",
       "      <td>0.024277</td>\n",
       "      <td>0.013832</td>\n",
       "      <td>0.006008</td>\n",
       "      <td>0.139038</td>\n",
       "      <td>0.326416</td>\n",
       "      <td>0.293213</td>\n",
       "      <td>0.139038</td>\n",
       "      <td>0.048926</td>\n",
       "      <td>...</td>\n",
       "      <td>0.479004</td>\n",
       "      <td>0.752441</td>\n",
       "      <td>0.553711</td>\n",
       "      <td>0.466064</td>\n",
       "      <td>0.114457</td>\n",
       "      <td>0.012878</td>\n",
       "      <td>0.016632</td>\n",
       "      <td>0.010063</td>\n",
       "      <td>0.002308</td>\n",
       "      <td>0.004278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00004b22eaeeeb0ec976890c1d9bfc14fd9427e98c4ee9a4693dd914fca22557</th>\n",
       "      <td>0.022018</td>\n",
       "      <td>0.038879</td>\n",
       "      <td>0.024414</td>\n",
       "      <td>0.012337</td>\n",
       "      <td>0.008096</td>\n",
       "      <td>0.514648</td>\n",
       "      <td>0.514648</td>\n",
       "      <td>0.419189</td>\n",
       "      <td>0.323730</td>\n",
       "      <td>0.070164</td>\n",
       "      <td>...</td>\n",
       "      <td>0.244995</td>\n",
       "      <td>0.605469</td>\n",
       "      <td>0.281738</td>\n",
       "      <td>0.005058</td>\n",
       "      <td>0.236115</td>\n",
       "      <td>0.006939</td>\n",
       "      <td>0.009323</td>\n",
       "      <td>0.006081</td>\n",
       "      <td>0.000601</td>\n",
       "      <td>0.003206</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 927 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    B_10_last  B_10_max  \\\n",
       "customer_ID                                                               \n",
       "00000469ba478561f23a92a868bd366de6f6527a684c9a2...   0.033600  0.063171   \n",
       "00001bf2e77ff879fab36aa4fac689b9ba411dae63ae397...   0.298828  0.303223   \n",
       "0000210045da4f81e5f122c6bde5c2a617d03eef67f82c5...   0.129150  0.298828   \n",
       "00003b41e58ede33b8daf61ab56d9952f17c9ad1c3976cf...   0.032135  0.032135   \n",
       "00004b22eaeeeb0ec976890c1d9bfc14fd9427e98c4ee9a...   0.022018  0.038879   \n",
       "\n",
       "                                                    B_10_mean  B_10_min  \\\n",
       "customer_ID                                                               \n",
       "00000469ba478561f23a92a868bd366de6f6527a684c9a2...   0.037079 -0.002918   \n",
       "00001bf2e77ff879fab36aa4fac689b9ba411dae63ae397...   0.298096  0.293457   \n",
       "0000210045da4f81e5f122c6bde5c2a617d03eef67f82c5...   0.192017  0.079224   \n",
       "00003b41e58ede33b8daf61ab56d9952f17c9ad1c3976cf...   0.024277  0.013832   \n",
       "00004b22eaeeeb0ec976890c1d9bfc14fd9427e98c4ee9a...   0.024414  0.012337   \n",
       "\n",
       "                                                    B_10_std  B_11_last  \\\n",
       "customer_ID                                                               \n",
       "00000469ba478561f23a92a868bd366de6f6527a684c9a2...  0.017798   0.005188   \n",
       "00001bf2e77ff879fab36aa4fac689b9ba411dae63ae397...  0.002682   0.002235   \n",
       "0000210045da4f81e5f122c6bde5c2a617d03eef67f82c5...  0.088889   0.003380   \n",
       "00003b41e58ede33b8daf61ab56d9952f17c9ad1c3976cf...  0.006008   0.139038   \n",
       "00004b22eaeeeb0ec976890c1d9bfc14fd9427e98c4ee9a...  0.008096   0.514648   \n",
       "\n",
       "                                                    B_11_max  B_11_mean  \\\n",
       "customer_ID                                                               \n",
       "00000469ba478561f23a92a868bd366de6f6527a684c9a2...  0.013306   0.006187   \n",
       "00001bf2e77ff879fab36aa4fac689b9ba411dae63ae397...  0.237061   0.035706   \n",
       "0000210045da4f81e5f122c6bde5c2a617d03eef67f82c5...  0.025375   0.009048   \n",
       "00003b41e58ede33b8daf61ab56d9952f17c9ad1c3976cf...  0.326416   0.293213   \n",
       "00004b22eaeeeb0ec976890c1d9bfc14fd9427e98c4ee9a...  0.514648   0.419189   \n",
       "\n",
       "                                                    B_11_min  B_11_std  ...  \\\n",
       "customer_ID                                                             ...   \n",
       "00000469ba478561f23a92a868bd366de6f6527a684c9a2...  0.003296  0.003371  ...   \n",
       "00001bf2e77ff879fab36aa4fac689b9ba411dae63ae397...  0.001258  0.061982  ...   \n",
       "0000210045da4f81e5f122c6bde5c2a617d03eef67f82c5...  0.001163  0.007781  ...   \n",
       "00003b41e58ede33b8daf61ab56d9952f17c9ad1c3976cf...  0.139038  0.048926  ...   \n",
       "00004b22eaeeeb0ec976890c1d9bfc14fd9427e98c4ee9a...  0.323730  0.070164  ...   \n",
       "\n",
       "                                                    S_8_last   S_8_max  \\\n",
       "customer_ID                                                              \n",
       "00000469ba478561f23a92a868bd366de6f6527a684c9a2...  0.464111  0.464111   \n",
       "00001bf2e77ff879fab36aa4fac689b9ba411dae63ae397...  0.768555  1.004883   \n",
       "0000210045da4f81e5f122c6bde5c2a617d03eef67f82c5...  0.122986  0.759766   \n",
       "00003b41e58ede33b8daf61ab56d9952f17c9ad1c3976cf...  0.479004  0.752441   \n",
       "00004b22eaeeeb0ec976890c1d9bfc14fd9427e98c4ee9a...  0.244995  0.605469   \n",
       "\n",
       "                                                    S_8_mean   S_8_min  \\\n",
       "customer_ID                                                              \n",
       "00000469ba478561f23a92a868bd366de6f6527a684c9a2...  0.271240  0.170776   \n",
       "00001bf2e77ff879fab36aa4fac689b9ba411dae63ae397...  0.840332  0.604980   \n",
       "0000210045da4f81e5f122c6bde5c2a617d03eef67f82c5...  0.336182  0.007782   \n",
       "00003b41e58ede33b8daf61ab56d9952f17c9ad1c3976cf...  0.553711  0.466064   \n",
       "00004b22eaeeeb0ec976890c1d9bfc14fd9427e98c4ee9a...  0.281738  0.005058   \n",
       "\n",
       "                                                     S_8_std  S_9_last  \\\n",
       "customer_ID                                                              \n",
       "00000469ba478561f23a92a868bd366de6f6527a684c9a2...  0.103693  0.016998   \n",
       "00001bf2e77ff879fab36aa4fac689b9ba411dae63ae397...  0.110109  0.018509   \n",
       "0000210045da4f81e5f122c6bde5c2a617d03eef67f82c5...  0.204347  0.009171   \n",
       "00003b41e58ede33b8daf61ab56d9952f17c9ad1c3976cf...  0.114457  0.012878   \n",
       "00004b22eaeeeb0ec976890c1d9bfc14fd9427e98c4ee9a...  0.236115  0.006939   \n",
       "\n",
       "                                                     S_9_max  S_9_mean  \\\n",
       "customer_ID                                                              \n",
       "00000469ba478561f23a92a868bd366de6f6527a684c9a2...  0.022949  0.015572   \n",
       "00001bf2e77ff879fab36aa4fac689b9ba411dae63ae397...  0.544434  0.155762   \n",
       "0000210045da4f81e5f122c6bde5c2a617d03eef67f82c5...  0.551270  0.081970   \n",
       "00003b41e58ede33b8daf61ab56d9952f17c9ad1c3976cf...  0.016632  0.010063   \n",
       "00004b22eaeeeb0ec976890c1d9bfc14fd9427e98c4ee9a...  0.009323  0.006081   \n",
       "\n",
       "                                                     S_9_min   S_9_std  \n",
       "customer_ID                                                             \n",
       "00000469ba478561f23a92a868bd366de6f6527a684c9a2...  0.010773  0.004110  \n",
       "00001bf2e77ff879fab36aa4fac689b9ba411dae63ae397...  0.018509  0.184704  \n",
       "0000210045da4f81e5f122c6bde5c2a617d03eef67f82c5...  0.001582  0.175943  \n",
       "00003b41e58ede33b8daf61ab56d9952f17c9ad1c3976cf...  0.002308  0.004278  \n",
       "00004b22eaeeeb0ec976890c1d9bfc14fd9427e98c4ee9a...  0.000601  0.003206  \n",
       "\n",
       "[5 rows x 927 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = generate_x_y('/kaggle/input/amex-agg-data-pickle/test_agg.pkl', test=True)\n",
    "\n",
    "# add columns that existin in train but not test \n",
    "X_test['D_64_last_-1'] = 0.0\n",
    "X_test = X_test.reindex(sorted(X_test.columns), axis=1)\n",
    "\n",
    "display(X_test.head())\n",
    "X_test.to_pickle('X_test_agg.pkl', compression='gzip')\n",
    "\n",
    "del X_test\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331e8848",
   "metadata": {
    "papermill": {
     "duration": 0.00398,
     "end_time": "2023-02-10T00:03:04.461794",
     "exception": false,
     "start_time": "2023-02-10T00:03:04.457814",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 849.155679,
   "end_time": "2023-02-10T00:03:05.192581",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-02-09T23:48:56.036902",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
